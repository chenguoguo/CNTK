=== Running mpiexec -n 3 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu DeviceId=-1 timestamping=true speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]] speechTrain=[reader=[prefetch=true]] numCPUThreads=8 precision=double speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] speechTrain=[SGD=[maxEpochs=4]] speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]] stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: May  3 2016 17:56:15
		Last modified date: Tue May  3 11:36:22 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
		Built by philly on 18750d26eb32
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
		Built time: May  3 2016 17:56:15
		Last modified date: Tue May  3 11:36:22 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
		Built by philly on 18750d26eb32
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
MPIWrapper: initializing MPI
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
-------------------------------------------------------------------
Build info: 

		Built time: May  3 2016 17:56:15
		Last modified date: Tue May  3 11:36:22 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
		Built by philly on 18750d26eb32
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
MPIWrapper: initializing MPI
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: all 3 nodes responded
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: all 3 nodes responded
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: all 3 nodes responded
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (after change)]: all 3 nodes responded
mpihelper: we are cog 2 in a gearbox of 3
ping [mpihelper]: 3 nodes pinging each other
ping [requestnodes (after change)]: all 3 nodes responded
mpihelper: we are cog 0 in a gearbox of 3
ping [mpihelper]: 3 nodes pinging each other
ping [requestnodes (after change)]: all 3 nodes responded
mpihelper: we are cog 1 in a gearbox of 3
ping [mpihelper]: 3 nodes pinging each other
ping [mpihelper]: all 3 nodes responded
ping [mpihelper]: all 3 nodes responded
ping [mpihelper]: all 3 nodes responded
05/03/2016 18:17:13: Redirecting stderr to file /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank0
05/03/2016 18:17:14: Redirecting stderr to file /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank1
05/03/2016 18:17:14: Redirecting stderr to file /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank2
--------------------------------------------------------------------------
mpiexec has exited due to process rank 0 with PID 673 on
node 87698aadbc9d exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.

--------------------------------------------------------------------------
MPI Rank 0: 05/03/2016 18:17:13: -------------------------------------------------------------------
MPI Rank 0: 05/03/2016 18:17:13: Build info: 
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: 		Built time: May  3 2016 17:56:15
MPI Rank 0: 05/03/2016 18:17:13: 		Last modified date: Tue May  3 11:36:22 2016
MPI Rank 0: 05/03/2016 18:17:13: 		Build type: release
MPI Rank 0: 05/03/2016 18:17:13: 		Build target: GPU
MPI Rank 0: 05/03/2016 18:17:13: 		With 1bit-SGD: no
MPI Rank 0: 05/03/2016 18:17:13: 		Math lib: acml
MPI Rank 0: 05/03/2016 18:17:13: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 05/03/2016 18:17:13: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 05/03/2016 18:17:13: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 05/03/2016 18:17:13: 		Build Branch: HEAD
MPI Rank 0: 05/03/2016 18:17:13: 		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
MPI Rank 0: 05/03/2016 18:17:13: 		Built by philly on 18750d26eb32
MPI Rank 0: 05/03/2016 18:17:13: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 05/03/2016 18:17:13: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Running on localhost at 2016/05/03 18:17:13
MPI Rank 0: 05/03/2016 18:17:13: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN  OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]  speechTrain=[reader=[prefetch=true]]  numCPUThreads=8  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 05/03/2016 18:17:13: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 0: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 0: speechTrain=[reader=[prefetch=true]]
MPI Rank 0: numCPUThreads=8
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 05/03/2016 18:17:13: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = -1
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 0: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 0: speechTrain=[reader=[prefetch=true]]
MPI Rank 0: numCPUThreads=8
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=-1
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=8
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [reader=[readerType=ExperimentalHTKMLFReader]] [reader=[prefetch=true]] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 05/03/2016 18:17:13: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 05/03/2016 18:17:13: Commands: speechTrain
MPI Rank 0: 05/03/2016 18:17:13: Precision = "double"
MPI Rank 0: 05/03/2016 18:17:13: Using 8 CPU threads.
MPI Rank 0: 05/03/2016 18:17:13: CNTKModelPath: /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 0: 05/03/2016 18:17:13: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 0: 05/03/2016 18:17:13: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: ##############################################################################
MPI Rank 0: 05/03/2016 18:17:13: #                                                                            #
MPI Rank 0: 05/03/2016 18:17:13: # Action "train"                                                             #
MPI Rank 0: 05/03/2016 18:17:13: #                                                                            #
MPI Rank 0: 05/03/2016 18:17:13: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: Reading script file glob_0000.scp ... 948 entries
MPI Rank 0: HTKDataDeserializer::HTKDataDeserializer: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: HTKDataDeserializer::HTKDataDeserializer: determined feature kind as 363-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: MLFDataDeserializer::MLFDataDeserializer: read 252734 sequences
MPI Rank 0: MLFDataDeserializer::MLFDataDeserializer: read 948 utterances
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Creating virgin network.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Created model with 25 nodes on CPU.
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Training criterion node(s):
MPI Rank 0: 05/03/2016 18:17:13: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x1303ea8: {[W0 Value[512 x 363]] }
MPI Rank 0: 0x13042e8: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x1305c98: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x130e9c8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x130eb88: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x1313e78: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x13275a8: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x132cd08: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x133d3e8: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x133ec38: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x13a3b78: {[Prior Value[132]] }
MPI Rank 0: 0x13c2218: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x13c23d8: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x13d1bc8: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x13d1d88: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x13d1f48: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x13d33d8: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x13f1668: {[features Value[363 x *]] }
MPI Rank 0: 0x1431b18: {[labels Value[132 x *]] }
MPI Rank 0: 0x1433cd8: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x1433e98: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 0x1439e48: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x1439fa8: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x143a108: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x143a268: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x143c148: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x143c2a8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x143d428: {[B2 Value[132 x 1]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:13: 	MeanOfFeatures = Mean()
MPI Rank 0: 05/03/2016 18:17:13: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 05/03/2016 18:17:13: 	Prior = Mean()
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:19: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:21: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:21: Starting minibatch loop.
MPI Rank 0: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: CrossEntropyWithSoftmax = 4.36628272 * 640; EvalErrorPrediction = 0.90937500 * 640; time = 0.5308s; samplesPerSecond = 1205.7
MPI Rank 0: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.15914991 * 640; EvalErrorPrediction = 0.89218750 * 640; time = 0.3306s; samplesPerSecond = 1935.8
MPI Rank 0: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.99837967 * 640; EvalErrorPrediction = 0.86875000 * 640; time = 0.3693s; samplesPerSecond = 1732.9
MPI Rank 0: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.86616341 * 640; EvalErrorPrediction = 0.86250000 * 640; time = 0.5229s; samplesPerSecond = 1223.9
MPI Rank 0: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: CrossEntropyWithSoftmax = 3.80082643 * 640; EvalErrorPrediction = 0.87968750 * 640; time = 0.3290s; samplesPerSecond = 1945.6
MPI Rank 0: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.73336112 * 640; EvalErrorPrediction = 0.87812500 * 640; time = 0.3342s; samplesPerSecond = 1915.0
MPI Rank 0: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.57119384 * 640; EvalErrorPrediction = 0.82031250 * 640; time = 0.3390s; samplesPerSecond = 1887.8
MPI Rank 0: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.44001005 * 640; EvalErrorPrediction = 0.81562500 * 640; time = 0.3708s; samplesPerSecond = 1725.9
MPI Rank 0: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: CrossEntropyWithSoftmax = 3.36131109 * 640; EvalErrorPrediction = 0.77343750 * 640; time = 0.3804s; samplesPerSecond = 1682.4
MPI Rank 0: 05/03/2016 18:17:25:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39817487 * 640; EvalErrorPrediction = 0.85000000 * 640; time = 0.5189s; samplesPerSecond = 1233.5
MPI Rank 0: 05/03/2016 18:17:25:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.25116276 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.3404s; samplesPerSecond = 1880.3
MPI Rank 0: 05/03/2016 18:17:26:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.35774005 * 640; EvalErrorPrediction = 0.79843750 * 640; time = 0.3362s; samplesPerSecond = 1903.4
MPI Rank 0: 05/03/2016 18:17:26:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: CrossEntropyWithSoftmax = 3.19791351 * 640; EvalErrorPrediction = 0.76406250 * 640; time = 0.3700s; samplesPerSecond = 1729.7
MPI Rank 0: 05/03/2016 18:17:26:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.06449990 * 640; EvalErrorPrediction = 0.71718750 * 640; time = 0.3663s; samplesPerSecond = 1747.0
MPI Rank 0: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.05357361 * 640; EvalErrorPrediction = 0.74218750 * 640; time = 0.3595s; samplesPerSecond = 1780.0
MPI Rank 0: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02144079 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.5480s; samplesPerSecond = 1167.9
MPI Rank 0: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: CrossEntropyWithSoftmax = 2.89890004 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.3444s; samplesPerSecond = 1858.4
MPI Rank 0: 05/03/2016 18:17:28:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74598358 * 640; EvalErrorPrediction = 0.68593750 * 640; time = 0.3179s; samplesPerSecond = 2013.5
MPI Rank 0: 05/03/2016 18:17:28:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.83604141 * 640; EvalErrorPrediction = 0.70625000 * 640; time = 0.3751s; samplesPerSecond = 1706.0
MPI Rank 0: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.62522562 * 640; EvalErrorPrediction = 0.64687500 * 640; time = 0.3640s; samplesPerSecond = 1758.3
MPI Rank 0: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: CrossEntropyWithSoftmax = 2.65507979 * 640; EvalErrorPrediction = 0.66562500 * 640; time = 0.3465s; samplesPerSecond = 1847.2
MPI Rank 0: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.59593989 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.5191s; samplesPerSecond = 1232.9
MPI Rank 0: 05/03/2016 18:17:30:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.51177605 * 640; EvalErrorPrediction = 0.62343750 * 640; time = 0.3584s; samplesPerSecond = 1785.6
MPI Rank 0: 05/03/2016 18:17:30:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42438840 * 640; EvalErrorPrediction = 0.63281250 * 640; time = 0.3573s; samplesPerSecond = 1791.2
MPI Rank 0: 05/03/2016 18:17:30:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: CrossEntropyWithSoftmax = 2.40372959 * 640; EvalErrorPrediction = 0.65156250 * 640; time = 0.3511s; samplesPerSecond = 1822.7
MPI Rank 0: 05/03/2016 18:17:31:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.48277420 * 640; EvalErrorPrediction = 0.63906250 * 640; time = 0.3486s; samplesPerSecond = 1836.1
MPI Rank 0: 05/03/2016 18:17:31:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.34181483 * 640; EvalErrorPrediction = 0.61718750 * 640; time = 0.5554s; samplesPerSecond = 1152.4
MPI Rank 0: 05/03/2016 18:17:32:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.22951559 * 640; EvalErrorPrediction = 0.57656250 * 640; time = 0.4501s; samplesPerSecond = 1421.9
MPI Rank 0: 05/03/2016 18:17:32:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: CrossEntropyWithSoftmax = 2.32715885 * 640; EvalErrorPrediction = 0.62031250 * 640; time = 0.3540s; samplesPerSecond = 1807.7
MPI Rank 0: 05/03/2016 18:17:33:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.21143816 * 640; EvalErrorPrediction = 0.61406250 * 640; time = 0.3297s; samplesPerSecond = 1941.1
MPI Rank 0: 05/03/2016 18:17:33:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.29118500 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.3610s; samplesPerSecond = 1773.0
MPI Rank 0: 05/03/2016 18:17:33:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.19155470 * 640; EvalErrorPrediction = 0.56406250 * 640; time = 0.3651s; samplesPerSecond = 1753.0
MPI Rank 0: 05/03/2016 18:17:33: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=12.5019s
MPI Rank 0: 05/03/2016 18:17:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:33: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:33: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Actual gradient aggregation time: 0.029402
MPI Rank 0: Async gradient aggregation wait time: 0.071179
MPI Rank 0: Actual gradient aggregation time: 0.017354
MPI Rank 0: 05/03/2016 18:17:34:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.09514596 * 2304; EvalErrorPrediction = 0.55989583 * 2304; time = 0.9286s; samplesPerSecond = 2481.1
MPI Rank 0: Async gradient aggregation wait time: 0.015812
MPI Rank 0: Actual gradient aggregation time: 0.019064
MPI Rank 0: Async gradient aggregation wait time: 0.014546
MPI Rank 0: Actual gradient aggregation time: 0.030847
MPI Rank 0: 05/03/2016 18:17:35:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.14762552 * 2560; EvalErrorPrediction = 0.58242187 * 2560; time = 0.7629s; samplesPerSecond = 3355.7
MPI Rank 0: Async gradient aggregation wait time: 1e-05
MPI Rank 0: Actual gradient aggregation time: 0.017703
MPI Rank 0: Async gradient aggregation wait time: 1e-05
MPI Rank 0: Actual gradient aggregation time: 0.020986
MPI Rank 0: 05/03/2016 18:17:36:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.19977785 * 2560; EvalErrorPrediction = 0.58867187 * 2560; time = 0.9203s; samplesPerSecond = 2781.7
MPI Rank 0: Async gradient aggregation wait time: 9e-06
MPI Rank 0: Actual gradient aggregation time: 0.018731
MPI Rank 0: Async gradient aggregation wait time: 9e-06
MPI Rank 0: Actual gradient aggregation time: 0.01109
MPI Rank 0: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.13471172 * 2560; EvalErrorPrediction = 0.59023437 * 2560; time = 0.6527s; samplesPerSecond = 3921.9
MPI Rank 0: Async gradient aggregation wait time: 1.2e-05
MPI Rank 0: Actual gradient aggregation time: 0.020241
MPI Rank 0: Async gradient aggregation wait time: 0.101386
MPI Rank 0: Actual gradient aggregation time: 0.00597
MPI Rank 0: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.07369296 * 2560; EvalErrorPrediction = 0.57382813 * 2560; time = 0.8482s; samplesPerSecond = 3018.0
MPI Rank 0: Async gradient aggregation wait time: 1.1e-05
MPI Rank 0: Actual gradient aggregation time: 0.011477
MPI Rank 0: Async gradient aggregation wait time: 0.040599
MPI Rank 0: Actual gradient aggregation time: 0.264378
MPI Rank 0: 05/03/2016 18:17:38:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.14944464 * 2560; EvalErrorPrediction = 0.57578125 * 2560; time = 1.0650s; samplesPerSecond = 2403.8
MPI Rank 0: Async gradient aggregation wait time: 1e-05
MPI Rank 0: Actual gradient aggregation time: 0.009145
MPI Rank 0: Async gradient aggregation wait time: 9e-06
MPI Rank 0: Actual gradient aggregation time: 0.050316
MPI Rank 0: 05/03/2016 18:17:39:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.09921664 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.7399s; samplesPerSecond = 3460.0
MPI Rank 0: Async gradient aggregation wait time: 8e-06
MPI Rank 0: Actual gradient aggregation time: 0.014008
MPI Rank 0: Async gradient aggregation wait time: 1e-05
MPI Rank 0: Actual gradient aggregation time: 0.010712
MPI Rank 0: 05/03/2016 18:17:40:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.04462189 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.6413s; samplesPerSecond = 3992.0
MPI Rank 0: Async gradient aggregation wait time: 0.056019
MPI Rank 0: Actual gradient aggregation time: 0.021519
MPI Rank 0: 05/03/2016 18:17:40: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.11636713 * 20480; EvalErrorPrediction = 0.57500000 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.71428s
MPI Rank 0: 05/03/2016 18:17:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:40: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:40: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 1.2e-05
MPI Rank 0: Actual gradient aggregation time: 0.009779
MPI Rank 0: Async gradient aggregation wait time: 1.2e-05
MPI Rank 0: Actual gradient aggregation time: 0.014794
MPI Rank 0: 05/03/2016 18:17:42:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.00619565 * 9216; EvalErrorPrediction = 0.55088976 * 9216; time = 2.0209s; samplesPerSecond = 4560.3
MPI Rank 0: Async gradient aggregation wait time: 1.1e-05
MPI Rank 0: Actual gradient aggregation time: 0.006482
MPI Rank 0: Async gradient aggregation wait time: 1e-05
MPI Rank 0: Actual gradient aggregation time: 0.050314
MPI Rank 0: 05/03/2016 18:17:44:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93824509 * 10240; EvalErrorPrediction = 0.53398437 * 10240; time = 2.3145s; samplesPerSecond = 4424.4
MPI Rank 0: 05/03/2016 18:17:45: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.97096281 * 20480; EvalErrorPrediction = 0.54194336 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=4.44623s
MPI Rank 0: 05/03/2016 18:17:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:45: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:45: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 1.2e-05
MPI Rank 0: Actual gradient aggregation time: 0.024841
MPI Rank 0: Async gradient aggregation wait time: 0.073388
MPI Rank 0: Actual gradient aggregation time: 0.071822
MPI Rank 0: 05/03/2016 18:17:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.91072859 * 9216; EvalErrorPrediction = 0.52365451 * 9216; time = 1.7940s; samplesPerSecond = 5137.2
MPI Rank 0: Async gradient aggregation wait time: 1.1e-05
MPI Rank 0: Actual gradient aggregation time: 0.009846
MPI Rank 0: Async gradient aggregation wait time: 1.1e-05
MPI Rank 0: Actual gradient aggregation time: 0.144756
MPI Rank 0: 05/03/2016 18:17:48:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.89799241 * 10240; EvalErrorPrediction = 0.52294922 * 10240; time = 1.8320s; samplesPerSecond = 5589.5
MPI Rank 0: Async gradient aggregation wait time: 0.013612
MPI Rank 0: 05/03/2016 18:17:48: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.90474356 * 20480; EvalErrorPrediction = 0.52290039 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=3.6891s
MPI Rank 0: 05/03/2016 18:17:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn'
MPI Rank 0: 05/03/2016 18:17:48: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:48: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 05/03/2016 18:17:48: __COMPLETED__
MPI Rank 1: 05/03/2016 18:17:14: -------------------------------------------------------------------
MPI Rank 1: 05/03/2016 18:17:14: Build info: 
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: 		Built time: May  3 2016 17:56:15
MPI Rank 1: 05/03/2016 18:17:14: 		Last modified date: Tue May  3 11:36:22 2016
MPI Rank 1: 05/03/2016 18:17:14: 		Build type: release
MPI Rank 1: 05/03/2016 18:17:14: 		Build target: GPU
MPI Rank 1: 05/03/2016 18:17:14: 		With 1bit-SGD: no
MPI Rank 1: 05/03/2016 18:17:14: 		Math lib: acml
MPI Rank 1: 05/03/2016 18:17:14: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 05/03/2016 18:17:14: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 05/03/2016 18:17:14: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 05/03/2016 18:17:14: 		Build Branch: HEAD
MPI Rank 1: 05/03/2016 18:17:14: 		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
MPI Rank 1: 05/03/2016 18:17:14: 		Built by philly on 18750d26eb32
MPI Rank 1: 05/03/2016 18:17:14: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 05/03/2016 18:17:14: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Running on localhost at 2016/05/03 18:17:14
MPI Rank 1: 05/03/2016 18:17:14: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN  OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]  speechTrain=[reader=[prefetch=true]]  numCPUThreads=8  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 05/03/2016 18:17:14: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 1: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 1: speechTrain=[reader=[prefetch=true]]
MPI Rank 1: numCPUThreads=8
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 05/03/2016 18:17:14: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = -1
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 1: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 1: speechTrain=[reader=[prefetch=true]]
MPI Rank 1: numCPUThreads=8
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=-1
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=8
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [reader=[readerType=ExperimentalHTKMLFReader]] [reader=[prefetch=true]] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 05/03/2016 18:17:14: Commands: speechTrain
MPI Rank 1: 05/03/2016 18:17:14: Precision = "double"
MPI Rank 1: 05/03/2016 18:17:14: Using 8 CPU threads.
MPI Rank 1: 05/03/2016 18:17:14: CNTKModelPath: /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 1: 05/03/2016 18:17:14: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 1: 05/03/2016 18:17:14: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: ##############################################################################
MPI Rank 1: 05/03/2016 18:17:14: #                                                                            #
MPI Rank 1: 05/03/2016 18:17:14: # Action "train"                                                             #
MPI Rank 1: 05/03/2016 18:17:14: #                                                                            #
MPI Rank 1: 05/03/2016 18:17:14: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: Reading script file glob_0000.scp ... 948 entries
MPI Rank 1: HTKDataDeserializer::HTKDataDeserializer: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: HTKDataDeserializer::HTKDataDeserializer: determined feature kind as 363-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: MLFDataDeserializer::MLFDataDeserializer: read 252734 sequences
MPI Rank 1: MLFDataDeserializer::MLFDataDeserializer: read 948 utterances
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Creating virgin network.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Created model with 25 nodes on CPU.
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Training criterion node(s):
MPI Rank 1: 05/03/2016 18:17:14: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x10f2e28: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x10f4cd8: {[labels Value[132 x *]] }
MPI Rank 1: 0x10f58b8: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x10f7088: {[features Value[363 x *]] }
MPI Rank 1: 0x1100c28: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x1103d68: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x110a668: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x113cd98: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x113cf88: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x113d0e8: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x113e238: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 0x11b0ad8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x11b0c98: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x11b0e58: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x11b1378: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x11b14c8: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x11b1bb8: {[Prior Value[132]] }
MPI Rank 1: 0x11b9bf8: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x1207b78: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x1209698: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x1226428: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x122c838: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x122d058: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x122d218: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x122d3d8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x122f988: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x122fb48: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x122fd08: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:14: 	MeanOfFeatures = Mean()
MPI Rank 1: 05/03/2016 18:17:14: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 05/03/2016 18:17:14: 	Prior = Mean()
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:15: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:21: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:21: Starting minibatch loop.
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: CrossEntropyWithSoftmax = 4.36628272 * 640; EvalErrorPrediction = 0.90937500 * 640; time = 0.1938s; samplesPerSecond = 3302.3
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.15914991 * 640; EvalErrorPrediction = 0.89218750 * 640; time = 0.1038s; samplesPerSecond = 6163.3
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.99837967 * 640; EvalErrorPrediction = 0.86875000 * 640; time = 0.1047s; samplesPerSecond = 6114.0
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.86616341 * 640; EvalErrorPrediction = 0.86250000 * 640; time = 0.1038s; samplesPerSecond = 6165.0
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: CrossEntropyWithSoftmax = 3.80082643 * 640; EvalErrorPrediction = 0.87968750 * 640; time = 0.1042s; samplesPerSecond = 6141.0
MPI Rank 1: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.73336112 * 640; EvalErrorPrediction = 0.87812500 * 640; time = 0.1036s; samplesPerSecond = 6177.2
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.57119384 * 640; EvalErrorPrediction = 0.82031250 * 640; time = 0.1044s; samplesPerSecond = 6128.4
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.44001005 * 640; EvalErrorPrediction = 0.81562500 * 640; time = 0.1046s; samplesPerSecond = 6115.9
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: CrossEntropyWithSoftmax = 3.36131109 * 640; EvalErrorPrediction = 0.77343750 * 640; time = 0.1060s; samplesPerSecond = 6040.0
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39817487 * 640; EvalErrorPrediction = 0.85000000 * 640; time = 0.1059s; samplesPerSecond = 6045.0
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.25116276 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.1089s; samplesPerSecond = 5877.3
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.35774005 * 640; EvalErrorPrediction = 0.79843750 * 640; time = 0.1058s; samplesPerSecond = 6047.9
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: CrossEntropyWithSoftmax = 3.19791351 * 640; EvalErrorPrediction = 0.76406250 * 640; time = 0.1058s; samplesPerSecond = 6050.5
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.06449990 * 640; EvalErrorPrediction = 0.71718750 * 640; time = 0.1059s; samplesPerSecond = 6041.9
MPI Rank 1: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.05357361 * 640; EvalErrorPrediction = 0.74218750 * 640; time = 0.1059s; samplesPerSecond = 6044.5
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02144079 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.1058s; samplesPerSecond = 6050.2
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: CrossEntropyWithSoftmax = 2.89890004 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.1057s; samplesPerSecond = 6057.0
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74598358 * 640; EvalErrorPrediction = 0.68593750 * 640; time = 0.1058s; samplesPerSecond = 6051.8
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.83604141 * 640; EvalErrorPrediction = 0.70625000 * 640; time = 0.1057s; samplesPerSecond = 6056.0
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.62522562 * 640; EvalErrorPrediction = 0.64687500 * 640; time = 0.1058s; samplesPerSecond = 6046.9
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: CrossEntropyWithSoftmax = 2.65507979 * 640; EvalErrorPrediction = 0.66562500 * 640; time = 0.1061s; samplesPerSecond = 6033.1
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.59593989 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.1081s; samplesPerSecond = 5922.5
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.51177605 * 640; EvalErrorPrediction = 0.62343750 * 640; time = 0.1058s; samplesPerSecond = 6047.4
MPI Rank 1: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42438840 * 640; EvalErrorPrediction = 0.63281250 * 640; time = 0.1055s; samplesPerSecond = 6063.8
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: CrossEntropyWithSoftmax = 2.40372959 * 640; EvalErrorPrediction = 0.65156250 * 640; time = 0.1063s; samplesPerSecond = 6018.2
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.48277420 * 640; EvalErrorPrediction = 0.63906250 * 640; time = 0.1075s; samplesPerSecond = 5954.9
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.34181483 * 640; EvalErrorPrediction = 0.61718750 * 640; time = 0.1066s; samplesPerSecond = 6005.7
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.22951559 * 640; EvalErrorPrediction = 0.57656250 * 640; time = 0.1070s; samplesPerSecond = 5979.9
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: CrossEntropyWithSoftmax = 2.32715885 * 640; EvalErrorPrediction = 0.62031250 * 640; time = 0.1063s; samplesPerSecond = 6022.9
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.21143816 * 640; EvalErrorPrediction = 0.61406250 * 640; time = 0.1057s; samplesPerSecond = 6056.9
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.29118500 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.1057s; samplesPerSecond = 6056.7
MPI Rank 1: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.19155470 * 640; EvalErrorPrediction = 0.56406250 * 640; time = 0.1057s; samplesPerSecond = 6057.6
MPI Rank 1: 05/03/2016 18:17:24: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=3.51796s
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:33: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:33: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Actual gradient aggregation time: 0.256751
MPI Rank 1: Async gradient aggregation wait time: 0.152524
MPI Rank 1: Actual gradient aggregation time: 0.017439
MPI Rank 1: 05/03/2016 18:17:34:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.09514596 * 2304; EvalErrorPrediction = 0.55989583 * 2304; time = 0.9111s; samplesPerSecond = 2528.9
MPI Rank 1: Async gradient aggregation wait time: 0.060633
MPI Rank 1: Actual gradient aggregation time: 0.023823
MPI Rank 1: Async gradient aggregation wait time: 0.141508
MPI Rank 1: Actual gradient aggregation time: 0.030909
MPI Rank 1: 05/03/2016 18:17:35:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.14762552 * 2560; EvalErrorPrediction = 0.58242187 * 2560; time = 0.7441s; samplesPerSecond = 3440.3
MPI Rank 1: Async gradient aggregation wait time: 0.032629
MPI Rank 1: Actual gradient aggregation time: 0.078841
MPI Rank 1: Async gradient aggregation wait time: 0.086116
MPI Rank 1: Actual gradient aggregation time: 0.074649
MPI Rank 1: 05/03/2016 18:17:36:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.19977785 * 2560; EvalErrorPrediction = 0.58867187 * 2560; time = 0.9154s; samplesPerSecond = 2796.7
MPI Rank 1: Async gradient aggregation wait time: 0.04271
MPI Rank 1: Actual gradient aggregation time: 0.057857
MPI Rank 1: Async gradient aggregation wait time: 0.032583
MPI Rank 1: Actual gradient aggregation time: 0.099574
MPI Rank 1: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.13471172 * 2560; EvalErrorPrediction = 0.59023437 * 2560; time = 0.6551s; samplesPerSecond = 3907.8
MPI Rank 1: Async gradient aggregation wait time: 0.036529
MPI Rank 1: Actual gradient aggregation time: 0.055498
MPI Rank 1: Async gradient aggregation wait time: 0.132228
MPI Rank 1: Actual gradient aggregation time: 0.013017
MPI Rank 1: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.07369296 * 2560; EvalErrorPrediction = 0.57382813 * 2560; time = 0.8666s; samplesPerSecond = 2954.0
MPI Rank 1: Async gradient aggregation wait time: 0.021536
MPI Rank 1: Actual gradient aggregation time: 0.051534
MPI Rank 1: Async gradient aggregation wait time: 0.343543
MPI Rank 1: Actual gradient aggregation time: 0.151395
MPI Rank 1: 05/03/2016 18:17:38:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.14944464 * 2560; EvalErrorPrediction = 0.57578125 * 2560; time = 1.0492s; samplesPerSecond = 2440.0
MPI Rank 1: Async gradient aggregation wait time: 0.041122
MPI Rank 1: Actual gradient aggregation time: 0.049106
MPI Rank 1: Async gradient aggregation wait time: 0.036614
MPI Rank 1: Actual gradient aggregation time: 0.111577
MPI Rank 1: 05/03/2016 18:17:39:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.09921664 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.7697s; samplesPerSecond = 3326.0
MPI Rank 1: Async gradient aggregation wait time: 0.002193
MPI Rank 1: Actual gradient aggregation time: 0.060973
MPI Rank 1: Async gradient aggregation wait time: 0.044073
MPI Rank 1: Actual gradient aggregation time: 0.080688
MPI Rank 1: 05/03/2016 18:17:40:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.04462189 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.5997s; samplesPerSecond = 4269.0
MPI Rank 1: Async gradient aggregation wait time: 0.088484
MPI Rank 1: Actual gradient aggregation time: 0.03975
MPI Rank 1: 05/03/2016 18:17:40: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.11636713 * 20480; EvalErrorPrediction = 0.57500000 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.64205s
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:40: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:40: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.151793
MPI Rank 1: Actual gradient aggregation time: 0.185264
MPI Rank 1: Async gradient aggregation wait time: 0.12537
MPI Rank 1: Actual gradient aggregation time: 0.177347
MPI Rank 1: 05/03/2016 18:17:42:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.00619565 * 9216; EvalErrorPrediction = 0.55088976 * 9216; time = 1.8249s; samplesPerSecond = 5050.0
MPI Rank 1: Async gradient aggregation wait time: 0.189029
MPI Rank 1: Actual gradient aggregation time: 0.215694
MPI Rank 1: Async gradient aggregation wait time: 0.10713
MPI Rank 1: Actual gradient aggregation time: 0.243509
MPI Rank 1: 05/03/2016 18:17:44:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93824509 * 10240; EvalErrorPrediction = 0.53398437 * 10240; time = 2.1309s; samplesPerSecond = 4805.4
MPI Rank 1: 05/03/2016 18:17:44: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.97096281 * 20480; EvalErrorPrediction = 0.54194336 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=4.35452s
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:45: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:45: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.07418
MPI Rank 1: Actual gradient aggregation time: 0.135066
MPI Rank 1: Async gradient aggregation wait time: 0.306501
MPI Rank 1: Actual gradient aggregation time: 0.098328
MPI Rank 1: 05/03/2016 18:17:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.91072859 * 9216; EvalErrorPrediction = 0.52365451 * 9216; time = 1.5884s; samplesPerSecond = 5802.0
MPI Rank 1: Async gradient aggregation wait time: 0.281448
MPI Rank 1: Actual gradient aggregation time: 0.1621
MPI Rank 1: Async gradient aggregation wait time: 0.084342
MPI Rank 1: Actual gradient aggregation time: 0.299371
MPI Rank 1: 05/03/2016 18:17:48:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.89799241 * 10240; EvalErrorPrediction = 0.52294922 * 10240; time = 1.9459s; samplesPerSecond = 5262.4
MPI Rank 1: Async gradient aggregation wait time: 0.035358
MPI Rank 1: 05/03/2016 18:17:48: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.90474356 * 20480; EvalErrorPrediction = 0.52290039 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=3.68894s
MPI Rank 1: 05/03/2016 18:17:48: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:48: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 05/03/2016 18:17:48: __COMPLETED__
MPI Rank 2: 05/03/2016 18:17:14: -------------------------------------------------------------------
MPI Rank 2: 05/03/2016 18:17:14: Build info: 
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: 		Built time: May  3 2016 17:56:15
MPI Rank 2: 05/03/2016 18:17:14: 		Last modified date: Tue May  3 11:36:22 2016
MPI Rank 2: 05/03/2016 18:17:14: 		Build type: release
MPI Rank 2: 05/03/2016 18:17:14: 		Build target: GPU
MPI Rank 2: 05/03/2016 18:17:14: 		With 1bit-SGD: no
MPI Rank 2: 05/03/2016 18:17:14: 		Math lib: acml
MPI Rank 2: 05/03/2016 18:17:14: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 2: 05/03/2016 18:17:14: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 2: 05/03/2016 18:17:14: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 2: 05/03/2016 18:17:14: 		Build Branch: HEAD
MPI Rank 2: 05/03/2016 18:17:14: 		Build SHA1: 571b092d60e131fd529081a5ed52af2dc815dc82
MPI Rank 2: 05/03/2016 18:17:14: 		Built by philly on 18750d26eb32
MPI Rank 2: 05/03/2016 18:17:14: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 2: 05/03/2016 18:17:14: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Running on localhost at 2016/05/03 18:17:14
MPI Rank 2: 05/03/2016 18:17:14: Command line: 
MPI Rank 2: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN  OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]  speechTrain=[reader=[prefetch=true]]  numCPUThreads=8  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 05/03/2016 18:17:14: precision = "float"
MPI Rank 2: command = speechTrain
MPI Rank 2: deviceId = $DeviceId$
MPI Rank 2: parallelTrain = true
MPI Rank 2: speechTrain = [
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = $DeviceId$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 2: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DeviceId=-1
MPI Rank 2: timestamping=true
MPI Rank 2: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 2: speechTrain=[reader=[prefetch=true]]
MPI Rank 2: numCPUThreads=8
MPI Rank 2: precision=double
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 2: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 05/03/2016 18:17:14: precision = "float"
MPI Rank 2: command = speechTrain
MPI Rank 2: deviceId = -1
MPI Rank 2: parallelTrain = true
MPI Rank 2: speechTrain = [
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = -1
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 2: OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DeviceId=-1
MPI Rank 2: timestamping=true
MPI Rank 2: speechTrain=[reader=[readerType=ExperimentalHTKMLFReader]]
MPI Rank 2: speechTrain=[reader=[prefetch=true]]
MPI Rank 2: numCPUThreads=8
MPI Rank 2: precision=double
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 2: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: cntk.cntk:command=speechTrain
MPI Rank 2: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/ExperimentalHtkmlfReader/DNN/ParallelNoQuantizationBufferedAsyncGradientAggregation/../../../DNN
MPI Rank 2: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 2: configparameters: cntk.cntk:deviceId=-1
MPI Rank 2: configparameters: cntk.cntk:numCPUThreads=8
MPI Rank 2: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 2: configparameters: cntk.cntk:precision=double
MPI Rank 2: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: configparameters: cntk.cntk:speechTrain=[
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = -1
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ] [reader=[readerType=ExperimentalHTKMLFReader]] [reader=[prefetch=true]] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: 
MPI Rank 2: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: configparameters: cntk.cntk:timestamping=true
MPI Rank 2: 05/03/2016 18:17:14: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 05/03/2016 18:17:14: Commands: speechTrain
MPI Rank 2: 05/03/2016 18:17:14: Precision = "double"
MPI Rank 2: 05/03/2016 18:17:14: Using 8 CPU threads.
MPI Rank 2: 05/03/2016 18:17:14: CNTKModelPath: /tmp/cntk-test-20160503181449.303380/Speech/ExperimentalHtkmlfReader/DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 2: 05/03/2016 18:17:14: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 2: 05/03/2016 18:17:14: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: ##############################################################################
MPI Rank 2: 05/03/2016 18:17:14: #                                                                            #
MPI Rank 2: 05/03/2016 18:17:14: # Action "train"                                                             #
MPI Rank 2: 05/03/2016 18:17:14: #                                                                            #
MPI Rank 2: 05/03/2016 18:17:14: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: CNTKCommandTrainBegin: speechTrain
MPI Rank 2: SimpleNetworkBuilder Using CPU
MPI Rank 2: Reading script file glob_0000.scp ... 948 entries
MPI Rank 2: HTKDataDeserializer::HTKDataDeserializer: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 2: HTKDataDeserializer::HTKDataDeserializer: determined feature kind as 363-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 2: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 2: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 2: MLFDataDeserializer::MLFDataDeserializer: read 252734 sequences
MPI Rank 2: MLFDataDeserializer::MLFDataDeserializer: read 948 utterances
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Creating virgin network.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 7 roots:
MPI Rank 2: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 2: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 2: 	InvStdOfFeatures = InvStdDev()
MPI Rank 2: 	MeanOfFeatures = Mean()
MPI Rank 2: 	PosteriorProb = Softmax()
MPI Rank 2: 	Prior = Mean()
MPI Rank 2: 	ScaledLogLikelihood = Minus()
MPI Rank 2: 
MPI Rank 2: Validating network. 25 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 2: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 2: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 2: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 2: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 2: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 2: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 2: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 2: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 2: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 2: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 2: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 2: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 2: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 2: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 2: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 2: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 2: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 2: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 2: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 2: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 2: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 2: 
MPI Rank 2: Validating network. 17 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Created model with 25 nodes on CPU.
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Training criterion node(s):
MPI Rank 2: 05/03/2016 18:17:14: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Evaluation criterion node(s):
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 
MPI Rank 2: Memory Sharing Structure:
MPI Rank 2: 
MPI Rank 2: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 2: 0x1c4f1d8: {[MeanOfFeatures Value[363]] }
MPI Rank 2: 0x1c4f3b8: {[InvStdOfFeatures Value[363]] }
MPI Rank 2: 0x1c4fb68: {[W2 Value[132 x 512]] }
MPI Rank 2: 0x1c5c088: {[EvalErrorPrediction Value[1]] }
MPI Rank 2: 0x1c63438: {[W0*features Value[512 x *]] }
MPI Rank 2: 0x1c635f8: {[LogOfPrior Value[132]] }
MPI Rank 2: 0x1c6f4d8: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 2: 0x1c6f698: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 2: 0x1ca13b8: {[features Value[363 x *]] }
MPI Rank 2: 0x1ceeb78: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 2: 0x1ceed38: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 2: 0x1ceeef8: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 2: 0x1cfff18: {[labels Value[132 x *]] }
MPI Rank 2: 0x1d1f1b8: {[B0 Value[512 x 1]] }
MPI Rank 2: 0x1d37f48: {[B2 Gradient[132 x 1]] }
MPI Rank 2: 0x1d457a8: {[W0 Value[512 x 363]] }
MPI Rank 2: 0x1d58e98: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 2: 0x1d590a8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 2: 0x1d59268: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 2: 0x1d5cde8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 2: 0x1d5cfa8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 2: 0x1d5d168: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 2: 0x1d66268: {[B1 Value[512 x 1]] }
MPI Rank 2: 0x1d6dc18: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 2: 0x1d6ddd8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 2: 0x1d6e3f8: {[W1 Value[512 x 512]] }
MPI Rank 2: 0x1d8ae38: {[B2 Value[132 x 1]] }
MPI Rank 2: 0x1d8e0c8: {[Prior Value[132]] }
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: Precomputing --> 3 PreCompute nodes found.
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:14: 	MeanOfFeatures = Mean()
MPI Rank 2: 05/03/2016 18:17:14: 	InvStdOfFeatures = InvStdDev()
MPI Rank 2: 05/03/2016 18:17:14: 	Prior = Mean()
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:21: Precomputing --> Completed.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:21: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:21: Starting minibatch loop.
MPI Rank 2: 05/03/2016 18:17:21:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: CrossEntropyWithSoftmax = 4.36628272 * 640; EvalErrorPrediction = 0.90937500 * 640; time = 0.2912s; samplesPerSecond = 2197.9
MPI Rank 2: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.15914991 * 640; EvalErrorPrediction = 0.89218750 * 640; time = 0.4430s; samplesPerSecond = 1444.6
MPI Rank 2: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.99837967 * 640; EvalErrorPrediction = 0.86875000 * 640; time = 0.2995s; samplesPerSecond = 2136.6
MPI Rank 2: 05/03/2016 18:17:22:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.86616341 * 640; EvalErrorPrediction = 0.86250000 * 640; time = 0.3414s; samplesPerSecond = 1874.5
MPI Rank 2: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: CrossEntropyWithSoftmax = 3.80082643 * 640; EvalErrorPrediction = 0.87968750 * 640; time = 0.4069s; samplesPerSecond = 1573.0
MPI Rank 2: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.73336112 * 640; EvalErrorPrediction = 0.87812500 * 640; time = 0.3578s; samplesPerSecond = 1788.9
MPI Rank 2: 05/03/2016 18:17:23:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.57119384 * 640; EvalErrorPrediction = 0.82031250 * 640; time = 0.3430s; samplesPerSecond = 1865.8
MPI Rank 2: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.44001005 * 640; EvalErrorPrediction = 0.81562500 * 640; time = 0.5425s; samplesPerSecond = 1179.8
MPI Rank 2: 05/03/2016 18:17:24:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: CrossEntropyWithSoftmax = 3.36131109 * 640; EvalErrorPrediction = 0.77343750 * 640; time = 0.3156s; samplesPerSecond = 2027.7
MPI Rank 2: 05/03/2016 18:17:25:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39817487 * 640; EvalErrorPrediction = 0.85000000 * 640; time = 0.3897s; samplesPerSecond = 1642.4
MPI Rank 2: 05/03/2016 18:17:25:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.25116276 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.4182s; samplesPerSecond = 1530.5
MPI Rank 2: 05/03/2016 18:17:25:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.35774005 * 640; EvalErrorPrediction = 0.79843750 * 640; time = 0.3946s; samplesPerSecond = 1622.0
MPI Rank 2: 05/03/2016 18:17:26:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: CrossEntropyWithSoftmax = 3.19791351 * 640; EvalErrorPrediction = 0.76406250 * 640; time = 0.5333s; samplesPerSecond = 1200.0
MPI Rank 2: 05/03/2016 18:17:26:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.06449990 * 640; EvalErrorPrediction = 0.71718750 * 640; time = 0.3297s; samplesPerSecond = 1941.2
MPI Rank 2: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.05357361 * 640; EvalErrorPrediction = 0.74218750 * 640; time = 0.3544s; samplesPerSecond = 1806.0
MPI Rank 2: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02144079 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.3695s; samplesPerSecond = 1732.2
MPI Rank 2: 05/03/2016 18:17:27:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: CrossEntropyWithSoftmax = 2.89890004 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.3098s; samplesPerSecond = 2065.9
MPI Rank 2: 05/03/2016 18:17:28:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74598358 * 640; EvalErrorPrediction = 0.68593750 * 640; time = 0.3440s; samplesPerSecond = 1860.4
MPI Rank 2: 05/03/2016 18:17:28:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.83604141 * 640; EvalErrorPrediction = 0.70625000 * 640; time = 0.5601s; samplesPerSecond = 1142.6
MPI Rank 2: 05/03/2016 18:17:28:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.62522562 * 640; EvalErrorPrediction = 0.64687500 * 640; time = 0.3037s; samplesPerSecond = 2107.6
MPI Rank 2: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: CrossEntropyWithSoftmax = 2.65507979 * 640; EvalErrorPrediction = 0.66562500 * 640; time = 0.3126s; samplesPerSecond = 2047.5
MPI Rank 2: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.59593989 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.3432s; samplesPerSecond = 1864.6
MPI Rank 2: 05/03/2016 18:17:29:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.51177605 * 640; EvalErrorPrediction = 0.62343750 * 640; time = 0.3358s; samplesPerSecond = 1905.6
MPI Rank 2: 05/03/2016 18:17:30:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42438840 * 640; EvalErrorPrediction = 0.63281250 * 640; time = 0.3475s; samplesPerSecond = 1841.7
MPI Rank 2: 05/03/2016 18:17:30:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: CrossEntropyWithSoftmax = 2.40372959 * 640; EvalErrorPrediction = 0.65156250 * 640; time = 0.5180s; samplesPerSecond = 1235.5
MPI Rank 2: 05/03/2016 18:17:31:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.48277420 * 640; EvalErrorPrediction = 0.63906250 * 640; time = 0.3048s; samplesPerSecond = 2099.9
MPI Rank 2: 05/03/2016 18:17:31:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.34181483 * 640; EvalErrorPrediction = 0.61718750 * 640; time = 0.3391s; samplesPerSecond = 1887.3
MPI Rank 2: 05/03/2016 18:17:31:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.22951559 * 640; EvalErrorPrediction = 0.57656250 * 640; time = 0.4149s; samplesPerSecond = 1542.6
MPI Rank 2: 05/03/2016 18:17:32:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: CrossEntropyWithSoftmax = 2.32715885 * 640; EvalErrorPrediction = 0.62031250 * 640; time = 0.3393s; samplesPerSecond = 1886.4
MPI Rank 2: 05/03/2016 18:17:32:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.21143816 * 640; EvalErrorPrediction = 0.61406250 * 640; time = 0.3185s; samplesPerSecond = 2009.3
MPI Rank 2: 05/03/2016 18:17:33:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.29118500 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.4962s; samplesPerSecond = 1289.8
MPI Rank 2: 05/03/2016 18:17:33:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.19155470 * 640; EvalErrorPrediction = 0.56406250 * 640; time = 0.3142s; samplesPerSecond = 2036.7
MPI Rank 2: 05/03/2016 18:17:33: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=12.1027s
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:33: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:33: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Actual gradient aggregation time: 0.175128
MPI Rank 2: Async gradient aggregation wait time: 0.117374
MPI Rank 2: Actual gradient aggregation time: 0.002975
MPI Rank 2: 05/03/2016 18:17:34:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.09514596 * 2304; EvalErrorPrediction = 0.55989583 * 2304; time = 0.9264s; samplesPerSecond = 2487.2
MPI Rank 2: Async gradient aggregation wait time: 7e-06
MPI Rank 2: Actual gradient aggregation time: 0.00293
MPI Rank 2: Async gradient aggregation wait time: 1e-05
MPI Rank 2: Actual gradient aggregation time: 0.002881
MPI Rank 2: 05/03/2016 18:17:35:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.14762552 * 2560; EvalErrorPrediction = 0.58242187 * 2560; time = 0.7463s; samplesPerSecond = 3430.1
MPI Rank 2: Async gradient aggregation wait time: 1.2e-05
MPI Rank 2: Actual gradient aggregation time: 0.064325
MPI Rank 2: Async gradient aggregation wait time: 0.072604
MPI Rank 2: Actual gradient aggregation time: 0.074621
MPI Rank 2: 05/03/2016 18:17:36:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.19977785 * 2560; EvalErrorPrediction = 0.58867187 * 2560; time = 0.8973s; samplesPerSecond = 2853.0
MPI Rank 2: Async gradient aggregation wait time: 0.030852
MPI Rank 2: Actual gradient aggregation time: 0.044373
MPI Rank 2: Async gradient aggregation wait time: 1e-05
MPI Rank 2: Actual gradient aggregation time: 0.080097
MPI Rank 2: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.13471172 * 2560; EvalErrorPrediction = 0.59023437 * 2560; time = 0.6665s; samplesPerSecond = 3840.9
MPI Rank 2: Async gradient aggregation wait time: 8e-06
MPI Rank 2: Actual gradient aggregation time: 0.042524
MPI Rank 2: Async gradient aggregation wait time: 0.085588
MPI Rank 2: Actual gradient aggregation time: 0.013021
MPI Rank 2: 05/03/2016 18:17:37:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.07369296 * 2560; EvalErrorPrediction = 0.57382813 * 2560; time = 0.8632s; samplesPerSecond = 2965.7
MPI Rank 2: Async gradient aggregation wait time: 1.2e-05
MPI Rank 2: Actual gradient aggregation time: 0.043282
MPI Rank 2: Async gradient aggregation wait time: 0.285633
MPI Rank 2: Actual gradient aggregation time: 0.264442
MPI Rank 2: 05/03/2016 18:17:38:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.14944464 * 2560; EvalErrorPrediction = 0.57578125 * 2560; time = 1.0412s; samplesPerSecond = 2458.6
MPI Rank 2: Async gradient aggregation wait time: 0.023156
MPI Rank 2: Actual gradient aggregation time: 0.035269
MPI Rank 2: Async gradient aggregation wait time: 0.006022
MPI Rank 2: Actual gradient aggregation time: 0.103537
MPI Rank 2: 05/03/2016 18:17:39:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.09921664 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.7819s; samplesPerSecond = 3274.2
MPI Rank 2: Async gradient aggregation wait time: 1.1e-05
MPI Rank 2: Actual gradient aggregation time: 0.026742
MPI Rank 2: Async gradient aggregation wait time: 0.013842
MPI Rank 2: Actual gradient aggregation time: 0.059232
MPI Rank 2: 05/03/2016 18:17:40:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.04462189 * 2560; EvalErrorPrediction = 0.56484375 * 2560; time = 0.6050s; samplesPerSecond = 4231.1
MPI Rank 2: Async gradient aggregation wait time: 0.086932
MPI Rank 2: Actual gradient aggregation time: 0.005437
MPI Rank 2: 05/03/2016 18:17:40: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.11636713 * 20480; EvalErrorPrediction = 0.57500000 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.64211s
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:40: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:40: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 1.2e-05
MPI Rank 2: Actual gradient aggregation time: 0.147008
MPI Rank 2: Async gradient aggregation wait time: 1.2e-05
MPI Rank 2: Actual gradient aggregation time: 0.130967
MPI Rank 2: 05/03/2016 18:17:42:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.00619565 * 9216; EvalErrorPrediction = 0.55088976 * 9216; time = 1.8697s; samplesPerSecond = 4929.2
MPI Rank 2: Async gradient aggregation wait time: 0.124091
MPI Rank 2: Actual gradient aggregation time: 0.211671
MPI Rank 2: Async gradient aggregation wait time: 0.00589
MPI Rank 2: Actual gradient aggregation time: 0.248853
MPI Rank 2: 05/03/2016 18:17:44:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93824509 * 10240; EvalErrorPrediction = 0.53398437 * 10240; time = 2.0930s; samplesPerSecond = 4892.5
MPI Rank 2: 05/03/2016 18:17:44: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.97096281 * 20480; EvalErrorPrediction = 0.54194336 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=4.35176s
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:45: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:45: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 1.1e-05
MPI Rank 2: Actual gradient aggregation time: 0.002676
MPI Rank 2: Async gradient aggregation wait time: 1.1e-05
MPI Rank 2: Actual gradient aggregation time: 0.003152
MPI Rank 2: 05/03/2016 18:17:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.91072859 * 9216; EvalErrorPrediction = 0.52365451 * 9216; time = 1.6066s; samplesPerSecond = 5736.2
MPI Rank 2: Async gradient aggregation wait time: 0.031845
MPI Rank 2: Actual gradient aggregation time: 0.162115
MPI Rank 2: Async gradient aggregation wait time: 1e-05
MPI Rank 2: Actual gradient aggregation time: 0.00666
MPI Rank 2: 05/03/2016 18:17:48:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.89799241 * 10240; EvalErrorPrediction = 0.52294922 * 10240; time = 2.0239s; samplesPerSecond = 5059.6
MPI Rank 2: Async gradient aggregation wait time: 0.009178
MPI Rank 2: 05/03/2016 18:17:48: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.90474356 * 20480; EvalErrorPrediction = 0.52290039 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=3.68899s
MPI Rank 2: 05/03/2016 18:17:48: CNTKCommandTrainEnd: speechTrain
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:48: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 05/03/2016 18:17:48: __COMPLETED__